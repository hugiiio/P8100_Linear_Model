---
title: "Linear regression"
output: html_document
---
```{r}
library(tidyverse)
library(p8105.datasets)
library(modelr)
library(mgcv)

set.seed(1)

```

```{r}
data("nyc_airbnb")

nyc_airbnb = 
  nyc_airbnb %>% 
  mutate(stars = review_scores_location / 2) %>% 
  rename(
    borough = neighbourhood_group,
    neighborhood = neighbourhood) %>% 
  filter(borough != "Staten Island") %>% 
  select(price, stars, borough, neighborhood, room_type)
```

##Fit a miodel

```{r}
nyc_airbnb %>% 
  ggplot(aes(x = stars, y = price, color = borough)) +
  geom_point()
```

fit a model we care about 
```{r, include = FALSE}

fit <-  lm(price ~ stars + borough, data = nyc_airbnb)

summary(fit)
summary(fit)$coef
coef(fit)
fitted.values(fit)
residuals(fit)

```

lets look at the results better
```{r}
broom::glance(fit)

broom::tidy(fit) %>% 
  select(-std.error, -statistic) %>% 
  mutate(
    term = str_replace(term, "borough", "Borough: ")
  ) %>% 
  knitr::kable(dight = 3)


```


##Be in control of factors

```{r}
nyc_airbnb <- 
  nyc_airbnb %>% 
  mutate(
    borough = fct_infreq(borough),
    room_type = fct_infreq(room_type))
    
  
```
Look at the plot again 
```{r}
fit = lm(price ~ stars + borough, data = nyc_airbnb)

broom::tidy(fit)
broom::glance(fit)
```

##Looking at diagnostocs

```{r}
modelr::add_residuals(nyc_airbnb, fit) %>% 
  ggplot(aes(x = borough, y = resid)) +
  geom_violin() +
  ylim(-500, 1500)


nyc_airbnb %>% 
  modelr::add_residuals(fit) %>% 
  ggplot(aes(x = stars, y = resid)) +
  geom_point() +
  facet_wrap(.~ borough)
  
```
##HT

this does t test by defualt
```{r}
fit %>% 
  broom::tidy()

```
what about significance of borough as a whole ?
```{r}
fit_nul <- lm(price ~stars, data = nyc_airbnb)

fit_alt <-  lm(price ~ stars + borough, data = nyc_airbnb)

anova(fit_nul, fit_alt) %>% 
  broom::tidy()
```

## Nest data, fit models

```{r}
fit <- lm(price ~ stars*borough + room_type*borough, data = nyc_airbnb)

broom::tidy(fit)

```
More exploratory but easier to understand
```{r}
nyc_airbnb %>% 
  nest(data = -borough) %>% 
  mutate(
    models = map(.x = data, ~lm(price ~stars, data = .x)),
    results = map(models, broom::tidy)
  ) %>% 
  select(-data, -models) %>% 
  unnest(results) %>% 
  filter(term == "stars")
```



##Model selection

```{r}
nonlin_df <- 
  tibble(
    id = 1:100,
    x = runif(100, 0, 1),
    y = 1 -10*(x - .3)^2 + rnorm(100, 0, .3)
  )
```
Look at the data
```{r}
nonlin_df %>% 
  ggplot(aes(x = x, y = y)) +
  geom_point()
```
##Cross validation--by hand
```{r}
train_df <- sample_n(nonlin_df, size = 80)
test_df <- anti_join(nonlin_df, train_df, by = "id")
```
buiuld models of varying levels of complexity
we will fit three models
```{r}
linear_mod <- lm(y ~ x, data = train_df)
smooth_mod <- gam(y ~ s(x), data = train_df)
wiggly_mod <- gam(y ~ s(x, k = 30), sp = 10e-6, data = train_df)


```
reading what we just did

```{r}
train_df %>% 
  add_predictions(linear_mod) %>% 
  ggplot(aes(x = x, y = y)) +
  geom_point() +
  geom_line(aes(y = pred), color = "red")

train_df %>% 
  add_predictions(smooth_mod) %>% 
  ggplot(aes(x = x, y = y)) +
  geom_point() +
  geom_line(aes(y = pred), color = "red")

train_df %>% 
  add_predictions(wiggly_mod) %>% 
  ggplot(aes(x = x, y = y)) +
  geom_point() +
  geom_line(aes(y = pred), color = "red")

train_df %>% 
  gather_predictions(linear_mod, smooth_mod, wiggly_mod) %>% 
  ggplot(aes(x = x, y = y)) +
  geom_point() +
  geom_line(aes(y = pred), color = "red") +
  facet_grid(.~model)


```
Looking at repdiction accuracy

```{r}
rmse(linear_mod, test_df)
rmse(smooth_mod, test_df)
rmse(wiggly_mod, test_df)


```

